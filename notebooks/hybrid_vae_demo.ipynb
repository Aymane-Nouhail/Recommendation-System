{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd73a2df",
   "metadata": {},
   "source": [
    "# Hybrid VAE Recommendation System - Complete Pipeline Demo\n",
    "\n",
    "This notebook demonstrates the complete pipeline for building and using a Hybrid Variational Autoencoder recommendation system that combines collaborative filtering with content-based filtering using SBERT embeddings.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The system consists of:\n",
    "1. **Data Preprocessing**: Loading and cleaning Amazon Reviews data\n",
    "2. **Dataset Building**: Creating user-item matrices and train/val/test splits\n",
    "3. **Embeddings Computation**: Using SBERT to encode item text\n",
    "4. **Model Training**: Training the Hybrid VAE\n",
    "5. **Evaluation**: Computing Recall@K and NDCG@K metrics\n",
    "6. **API Usage**: Serving recommendations via FastAPI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b646adf6",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3466c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import our custom modules\n",
    "from preprocessing import preprocess_amazon_reviews\n",
    "from build_dataset import build_recommendation_dataset\n",
    "from compute_embeddings import compute_item_embeddings\n",
    "from train_vae import train_hybrid_vae\n",
    "from evaluate import evaluate_recommendation_model\n",
    "from utils import *\n",
    "\n",
    "# Set up logging\n",
    "setup_logging(\"INFO\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f25fc16",
   "metadata": {},
   "source": [
    "## 1. Data Preprocessing\n",
    "\n",
    "First, we'll load and preprocess the Amazon Reviews dataset. This step:\n",
    "- Loads JSONL data\n",
    "- Cleans missing values\n",
    "- Creates `item_text` field by combining title and review text\n",
    "- Converts ratings to binary (rating >= 4 ‚Üí 1)\n",
    "- Filters users and items with minimum interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9700a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "data_dir = Path('../data')\n",
    "raw_data_path = data_dir / 'reviews.jsonl'  # Your raw Amazon Reviews data\n",
    "processed_data_path = data_dir / 'cleaned_reviews.jsonl'\n",
    "\n",
    "# Check if raw data exists\n",
    "if not raw_data_path.exists():\n",
    "    print(f\"‚ö†Ô∏è  Raw data not found at {raw_data_path}\")\n",
    "    print(\"Please place your Amazon Reviews JSONL file there to continue.\")\n",
    "    print(\"For demo purposes, we'll create a small sample dataset.\")\n",
    "    \n",
    "    # Create a small sample dataset for demonstration\n",
    "    sample_data = []\n",
    "    for i in range(1000):\n",
    "        sample_data.append({\n",
    "            'user_id': f'user_{i % 100}',\n",
    "            'asin': f'item_{i % 50}',\n",
    "            'rating': np.random.choice([3, 4, 5], p=[0.2, 0.4, 0.4]),\n",
    "            'title': f'Product {i % 50} Title',\n",
    "            'text': f'This is a review for product {i % 50}. Great quality and value.',\n",
    "            'timestamp': 1600000000 + i * 1000\n",
    "        })\n",
    "    \n",
    "    # Save sample data\n",
    "    with open(raw_data_path, 'w') as f:\n",
    "        for item in sample_data:\n",
    "            f.write(json.dumps(item) + '\\n')\n",
    "    \n",
    "    print(f\"‚úÖ Created sample dataset with {len(sample_data)} interactions\")\n",
    "\n",
    "print(f\"Raw data available at: {raw_data_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9ad0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run preprocessing\n",
    "print(\"üîÑ Starting data preprocessing...\")\n",
    "\n",
    "preprocess_amazon_reviews(\n",
    "    input_path=str(raw_data_path),\n",
    "    output_path=str(processed_data_path),\n",
    "    min_user_interactions=3,  # Lower threshold for demo\n",
    "    min_item_interactions=3,\n",
    "    rating_threshold=4.0\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Preprocessing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50b194d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and examine the preprocessed data\n",
    "df = pd.read_csv(processed_data_path.with_suffix('.csv'))\n",
    "\n",
    "print(f\"Preprocessed dataset shape: {df.shape}\")\n",
    "print(f\"Unique users: {df['user_id'].nunique()}\")\n",
    "print(f\"Unique items: {df['asin'].nunique()}\")\n",
    "print(f\"Positive interactions: {df['binary_rating'].sum()}\")\n",
    "\n",
    "# Display sample data\n",
    "print(\"\\nSample data:\")\n",
    "display(df.head())\n",
    "\n",
    "# Compute and display statistics\n",
    "stats = compute_dataset_statistics(df)\n",
    "print(\"\\nDataset Statistics:\")\n",
    "for key, value in stats.items():\n",
    "    if isinstance(value, dict):\n",
    "        print(f\"{key}:\")\n",
    "        for subkey, subvalue in value.items():\n",
    "            print(f\"  {subkey}: {subvalue:.2f}\")\n",
    "    else:\n",
    "        print(f\"{key}: {value:.4f}\" if isinstance(value, float) else f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b934f9",
   "metadata": {},
   "source": [
    "## 2. Dataset Building\n",
    "\n",
    "Next, we'll create the user-item interaction matrix and train/validation/test splits using leave-one-out methodology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ac624e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the recommendation dataset\n",
    "dataset_dir = data_dir / 'processed_dataset'\n",
    "\n",
    "print(\"üîÑ Building recommendation dataset...\")\n",
    "\n",
    "build_recommendation_dataset(\n",
    "    input_path=str(processed_data_path.with_suffix('.csv')),\n",
    "    output_dir=str(dataset_dir),\n",
    "    add_negatives=True,\n",
    "    n_negatives_per_positive=2  # Lower for demo\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Dataset building complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d53cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the created dataset\n",
    "train_df = pd.read_csv(dataset_dir / 'train.csv')\n",
    "val_df = pd.read_csv(dataset_dir / 'val.csv')\n",
    "test_df = pd.read_csv(dataset_dir / 'test.csv')\n",
    "\n",
    "# Load dataset statistics\n",
    "with open(dataset_dir / 'dataset_stats.pkl', 'rb') as f:\n",
    "    dataset_stats = pickle.load(f)\n",
    "\n",
    "print(\"Dataset Splits:\")\n",
    "print(f\"Train: {len(train_df):,} interactions\")\n",
    "print(f\"Val: {len(val_df):,} interactions\")\n",
    "print(f\"Test: {len(test_df):,} interactions\")\n",
    "\n",
    "print(\"\\nDataset Statistics:\")\n",
    "for key, value in dataset_stats.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# Validate data consistency\n",
    "consistency_results = validate_data_consistency(str(dataset_dir))\n",
    "print(\"\\nData Consistency Check:\")\n",
    "for check, passed in consistency_results.items():\n",
    "    status = \"‚úÖ\" if passed else \"‚ùå\"\n",
    "    print(f\"{status} {check}: {passed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d8f3dc",
   "metadata": {},
   "source": [
    "## 3. Compute Item Embeddings\n",
    "\n",
    "We'll use SBERT to create dense vector representations of items based on their text (title + review text)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4d9b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute item embeddings using SBERT\n",
    "embeddings_dir = Path('../embeddings')\n",
    "embeddings_path = embeddings_dir / 'item_embeddings.npy'\n",
    "\n",
    "print(\"üîÑ Computing item embeddings with SBERT...\")\n",
    "print(\"This may take a few minutes depending on the dataset size.\")\n",
    "\n",
    "compute_item_embeddings(\n",
    "    input_path=str(processed_data_path.with_suffix('.csv')),\n",
    "    output_path=str(embeddings_path),\n",
    "    model_name=\"all-MiniLM-L6-v2\",\n",
    "    batch_size=16,  # Smaller batch size for demo\n",
    "    device='cpu'  # Use CPU for demo\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Embeddings computation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ed06a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the computed embeddings\n",
    "from compute_embeddings import load_embeddings\n",
    "\n",
    "embeddings, item_to_idx, idx_to_item = load_embeddings(\n",
    "    str(embeddings_path),\n",
    "    str(embeddings_path.with_name('item_embeddings_mappings.pkl'))\n",
    ")\n",
    "\n",
    "print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "print(f\"Number of items: {len(item_to_idx)}\")\n",
    "print(f\"Embedding dimension: {embeddings.shape[1]}\")\n",
    "\n",
    "# Show some statistics about embeddings\n",
    "print(f\"\\nEmbedding Statistics:\")\n",
    "print(f\"Mean: {embeddings.mean():.4f}\")\n",
    "print(f\"Std: {embeddings.std():.4f}\")\n",
    "print(f\"Min: {embeddings.min():.4f}\")\n",
    "print(f\"Max: {embeddings.max():.4f}\")\n",
    "\n",
    "# Plot embedding distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(embeddings.flatten(), bins=50, alpha=0.7)\n",
    "plt.title('Distribution of Embedding Values')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "norms = np.linalg.norm(embeddings, axis=1)\n",
    "plt.hist(norms, bins=30, alpha=0.7)\n",
    "plt.title('Distribution of Embedding Norms')\n",
    "plt.xlabel('L2 Norm')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3981f4",
   "metadata": {},
   "source": [
    "## 4. Model Training\n",
    "\n",
    "Now we'll train the Hybrid VAE model that combines collaborative filtering with the item embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4185bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Hybrid VAE model\n",
    "models_dir = Path('../models')\n",
    "experiment_name = 'hybrid_vae_demo'\n",
    "model_output_dir = models_dir / experiment_name\n",
    "\n",
    "print(\"üîÑ Training Hybrid VAE model...\")\n",
    "print(\"This will take several minutes. Check the progress above.\")\n",
    "\n",
    "train_hybrid_vae(\n",
    "    data_dir=str(dataset_dir),\n",
    "    embeddings_path=str(embeddings_path),\n",
    "    output_dir=str(model_output_dir),\n",
    "    latent_dim=64,  # Smaller for demo\n",
    "    hidden_dims=[128, 64],  # Smaller for demo\n",
    "    batch_size=64,  # Smaller for demo\n",
    "    epochs=20,  # Fewer epochs for demo\n",
    "    learning_rate=0.001,\n",
    "    beta=0.2,\n",
    "    dropout=0.5,\n",
    "    patience=5,\n",
    "    device='cpu'  # Use CPU for demo\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f674c395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze training history\n",
    "with open(model_output_dir / 'training_history.json', 'r') as f:\n",
    "    history = json.load(f)\n",
    "\n",
    "print(\"Training Summary:\")\n",
    "print(f\"Final training loss: {history['train_losses'][-1]:.4f}\")\n",
    "if history['val_losses']:\n",
    "    print(f\"Final validation loss: {history['val_losses'][-1]:.4f}\")\n",
    "print(f\"Best validation loss: {min(history['val_losses']) if history['val_losses'] else 'N/A'}\")\n",
    "\n",
    "# Plot training curves\n",
    "plot_training_history(history, save_path=str(model_output_dir / 'training_plot.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f29590",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation\n",
    "\n",
    "Let's evaluate the trained model using Recall@K and NDCG@K metrics on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66306a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "best_model_path = model_output_dir / 'best_model.pth'\n",
    "\n",
    "print(\"üîÑ Evaluating model performance...\")\n",
    "\n",
    "results = evaluate_recommendation_model(\n",
    "    model_path=str(best_model_path),\n",
    "    data_dir=str(dataset_dir),\n",
    "    embeddings_path=str(embeddings_path),\n",
    "    k_values=[5, 10, 20],\n",
    "    device='cpu'\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Evaluation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f972517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display evaluation results\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"EVALUATION RESULTS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for k in [5, 10, 20]:\n",
    "    if k in results:\n",
    "        metrics = results[k]\n",
    "        print(f\"\\n@{k}:\")\n",
    "        print(f\"  Recall:    {metrics['recall']:.4f}\")\n",
    "        print(f\"  NDCG:      {metrics['ndcg']:.4f}\")\n",
    "        print(f\"  Hit Ratio: {metrics['hit_ratio']:.4f}\")\n",
    "\n",
    "# Save results\n",
    "with open(model_output_dir / 'evaluation_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(f\"\\nüìä Results saved to: {model_output_dir / 'evaluation_results.json'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c2a039",
   "metadata": {},
   "source": [
    "## 6. Generate Sample Recommendations\n",
    "\n",
    "Let's generate some sample recommendations to see the model in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02109126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model for inference\n",
    "from evaluate import load_model_from_checkpoint, RecommendationEvaluator\n",
    "\n",
    "# Load data and model\n",
    "interaction_matrix, train_df, val_df, mappings = load_training_data(str(dataset_dir))\n",
    "user_to_idx = mappings['user_to_idx']\n",
    "item_to_idx = mappings['item_to_idx']\n",
    "idx_to_user = mappings['idx_to_user']\n",
    "idx_to_item = mappings['idx_to_item']\n",
    "\n",
    "model = load_model_from_checkpoint(str(best_model_path), embeddings, torch.device('cpu'))\n",
    "\n",
    "# Create evaluator for generating recommendations\n",
    "evaluator = RecommendationEvaluator(\n",
    "    model=model,\n",
    "    interaction_matrix=interaction_matrix,\n",
    "    user_to_idx=user_to_idx,\n",
    "    item_to_idx=item_to_idx,\n",
    "    device=torch.device('cpu')\n",
    ")\n",
    "\n",
    "print(\"Model loaded and ready for recommendations!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0503d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate recommendations for sample users\n",
    "sample_users = list(user_to_idx.keys())[:5]  # First 5 users\n",
    "\n",
    "print(\"Sample Recommendations:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for user_id in sample_users:\n",
    "    if user_id in user_to_idx:\n",
    "        user_idx = user_to_idx[user_id]\n",
    "        \n",
    "        # Get user's interaction history\n",
    "        user_items = interaction_matrix[user_idx].nonzero()[1]\n",
    "        interacted_items = [idx_to_item[item_idx] for item_idx in user_items[:5]]\n",
    "        \n",
    "        # Generate recommendations\n",
    "        recommended_indices, scores = evaluator.get_user_recommendations(user_idx, top_k=10)\n",
    "        recommended_items = [(idx_to_item[idx], scores[i]) \n",
    "                           for i, idx in enumerate(recommended_indices[:5])]\n",
    "        \n",
    "        print(f\"\\nUser: {user_id}\")\n",
    "        print(f\"Items interacted with: {interacted_items}\")\n",
    "        print(\"Top 5 Recommendations:\")\n",
    "        for i, (item_id, score) in enumerate(recommended_items, 1):\n",
    "            print(f\"  {i}. {item_id} (score: {score:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cded9095",
   "metadata": {},
   "source": [
    "## 7. API Usage Demo\n",
    "\n",
    "Finally, let's demonstrate how to use the FastAPI server for serving recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846ed6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: In practice, you would run the API server in a separate process\n",
    "# Here we'll simulate the API functionality\n",
    "\n",
    "from api import create_app\n",
    "import requests\n",
    "import json\n",
    "\n",
    "print(\"üîÑ Setting up API demo...\")\n",
    "\n",
    "# Create the FastAPI app (this loads the model)\n",
    "try:\n",
    "    app = create_app(\n",
    "        model_path=str(best_model_path),\n",
    "        data_dir=str(dataset_dir),\n",
    "        embeddings_path=str(embeddings_path),\n",
    "        device_name='cpu'\n",
    "    )\n",
    "    print(\"‚úÖ API app created successfully!\")\n",
    "    print(\"\\nTo run the API server, use:\")\n",
    "    print(f\"python ../src/api.py --model {best_model_path} --data {dataset_dir} --embeddings {embeddings_path}\")\n",
    "    print(\"\\nThen you can make requests to http://localhost:8000\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error creating API app: {e}\")\n",
    "    print(\"This is expected in notebook environment. Run the API server separately.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874c51b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example API requests (you would use these when the server is running)\n",
    "\n",
    "print(\"Example API Usage:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Health check\n",
    "print(\"1. Health Check:\")\n",
    "print(\"GET /health\")\n",
    "print(\"Response: {\\\"status\\\": \\\"healthy\\\", \\\"model_loaded\\\": true, ...}\")\n",
    "\n",
    "# Get recommendations\n",
    "print(\"\\n2. Get Recommendations:\")\n",
    "print(\"POST /recommend\")\n",
    "example_request = {\n",
    "    \"user_id\": list(user_to_idx.keys())[0],\n",
    "    \"top_k\": 10,\n",
    "    \"exclude_seen\": True\n",
    "}\n",
    "print(f\"Request Body: {json.dumps(example_request, indent=2)}\")\n",
    "print(\"Response: {\\\"user_id\\\": \\\"...\\\", \\\"recommendations\\\": [...], ...}\")\n",
    "\n",
    "# User profile\n",
    "print(\"\\n3. Get User Profile:\")\n",
    "print(f\"GET /users/{list(user_to_idx.keys())[0]}/profile\")\n",
    "print(\"Response: {\\\"user_id\\\": \\\"...\\\", \\\"total_interactions\\\": 42, ...}\")\n",
    "\n",
    "# Batch recommendations\n",
    "print(\"\\n4. Batch Recommendations:\")\n",
    "print(\"POST /recommend/batch\")\n",
    "batch_request = {\n",
    "    \"user_ids\": list(user_to_idx.keys())[:3],\n",
    "    \"top_k\": 5\n",
    "}\n",
    "print(f\"Request Body: {json.dumps(batch_request, indent=2)}\")\n",
    "\n",
    "print(\"\\nüí° Start the API server and use curl or any HTTP client to test these endpoints!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdc24f3",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we've demonstrated the complete pipeline for building a Hybrid VAE recommendation system:\n",
    "\n",
    "1. **‚úÖ Data Preprocessing**: Cleaned and prepared Amazon Reviews data\n",
    "2. **‚úÖ Dataset Building**: Created user-item matrices and proper train/val/test splits\n",
    "3. **‚úÖ Embeddings**: Generated SBERT embeddings for item text\n",
    "4. **‚úÖ Model Training**: Trained the Hybrid VAE combining collaborative and content-based filtering\n",
    "5. **‚úÖ Evaluation**: Measured performance using Recall@K and NDCG@K\n",
    "6. **‚úÖ Recommendations**: Generated sample recommendations\n",
    "7. **‚úÖ API Setup**: Demonstrated how to serve the model via FastAPI\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. **Scale Up**: Use larger datasets and adjust hyperparameters\n",
    "2. **Hyperparameter Tuning**: Experiment with different latent dimensions, learning rates, etc.\n",
    "3. **Advanced Features**: Add user features, temporal dynamics, or cold-start handling\n",
    "4. **Production**: Deploy the API with proper monitoring and scaling\n",
    "5. **A/B Testing**: Compare with other recommendation algorithms\n",
    "\n",
    "### Key Benefits of This Approach:\n",
    "\n",
    "- **Hybrid**: Combines collaborative filtering strength with content understanding\n",
    "- **Scalable**: VAE approach handles sparse data well\n",
    "- **Interpretable**: Item embeddings provide insight into content relationships\n",
    "- **Production-Ready**: Complete API for serving recommendations\n",
    "- **Extensible**: Modular design allows easy improvements and experiments"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
